# RAG Pipeline Environment Configuration
# Copy this file to .env and modify as needed

# Ollama Configuration
# The model to use for LLM generation
OLLAMA_MODEL=mistral:7b

# The Ollama server URL
OLLAMA_URL=http://ollama.ariesview.com:11434

# Weaviate Configuration
# Weaviate server host
WEAVIATE_HOST=weaviate.ariesview.com

# Weaviate HTTP port
WEAVIATE_HTTP_PORT=8084

# Weaviate gRPC port
WEAVIATE_GRPC_PORT=50051

# Security settings (true/false)
WEAVIATE_HTTP_SECURE=false
WEAVIATE_GRPC_SECURE=false

# Example alternative configurations:
# OLLAMA_MODEL=llama3:latest
# OLLAMA_MODEL=gemma2:9b
# OLLAMA_MODEL=codellama:7b
# OLLAMA_URL=http://localhost:11434

# For local development:
# WEAVIATE_HOST=localhost
# WEAVIATE_HTTP_PORT=8080
# WEAVIATE_GRPC_PORT=50051

# For secured Weaviate instances:
# WEAVIATE_HTTP_SECURE=true
# WEAVIATE_GRPC_SECURE=true 